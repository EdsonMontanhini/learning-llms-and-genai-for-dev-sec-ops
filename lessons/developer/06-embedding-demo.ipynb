{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we got the document loaded & parsed , the next step is to calculate an \"embedding\" of that text. \n",
    "An embedding in it's simplest form is a multi dimensional mathematical vector that calculates the similarity of a piece of text. Topics and content that are similar have vectors that are close together. \n",
    "\n",
    "Embeddings enhance traditional search engines that use keywords or synonyms. Both have their place, but in this example we'll use embeddings as a way to calculate the proximity of texts.\n",
    "\n",
    "Why similarity you might ask ? Well RAG allows us to provide and LLM more context about a subject when we ask it a question. This context is done by looking up documents that have similarity and giving that information. So in this section we're laying the groundwork for that end-goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (0.0.281)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp311-cp311-macosx_11_0_arm64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.4/761.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openai in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary packages - tiktoken is used for calculating tokens\n",
    "%pip install langchain tiktoken openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example we have a bunch of texts and calculate embeddings with them.\n",
    "There are many different flavors of embeddings. Some work better with long texts, some better with multi lingual texts. Often llm providers will also provide an API to calculate embeddings through their service.\n",
    "They are not per se the best for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings calculated: 5\n",
      "Vectorsize of first embedding :1536\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/modules/data_connection/text_embedding/\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Embeddings calculated: {len(embeddings)}\")\n",
    "print(f\"Vectorsize of first embedding :{len(embeddings[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to calculating the embeddings from documents, we could also calculate that of a question.\n",
    "We assume that through that we can find the documents that are best to provide the answer.\n",
    "In this case the vector size is 1536."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorsize of query text embedding :1536\n"
     ]
    }
   ],
   "source": [
    "# calculate the embedding of the query\n",
    "embedded_query_results = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "print(f\"Vectorsize of query text embedding :{len(embedded_query_results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "london-devops-VW7lFx7f-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
